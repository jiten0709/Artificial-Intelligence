{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Model for QA Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (1.58.1)\n",
      "Requirement already satisfied: pinecone-client in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (5.0.1)\n",
      "Requirement already satisfied: torch in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pinecone-client) (2024.12.14)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: filelock in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: networkx in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai pinecone-client torch transformers datasets\n",
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hi/Downloads/AiSence/venv/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "your .env file should look like this:\n",
    "\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "PINECONE_API_KEY=your_pinecone_api_key\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone_client = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "\n",
    "# Define index name\n",
    "INDEX_NAME = \"business-qa-bot\"\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if INDEX_NAME not in pinecone_client.list_indexes():\n",
    "    pinecone_client.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"  # Adjust to your Pinecone environment\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pinecone_client.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a business-related dataset\n",
    "# Replace this with a dataset that contains Q&A pairs for the specific business domain\n",
    "\n",
    "data = load_dataset(\"ArunSharmaaaaa/business_for_chatbot\", split=\"train[:1000]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<s> [INST] business context, what factors influence work-life integration? [/INST] Hsieh explored diverse interests like playing poker that expanded his business perspectives while maintaining a holistic view on achieving happiness professionally and personally.</s>': '<s> [INST] could expanding habitual spaces increase mentions ? [/INST] Associating a product with a strong existing trigger outside its normal habitat, like pairing a candy with coffee breaks, can increase verbal mentions by linking it to something regularly thought of in a new context.</s>'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare documents for indexing\n",
    "documents = [\n",
    "    {\"id\": str(i), \n",
    "     \"context\": list(qa.keys())[0].split('[/INST]')[0].replace('<s> [INST] ', '').strip(),  # Extract the question\n",
    "     \"answer\": list(qa.values())[0].split('[/INST]')[1].replace(' [/INST]', '').replace('</s>', '').strip()}  # Extract the answer\n",
    "    for i, qa in enumerate(data)\n",
    "]\n",
    "\n",
    "# Extract only unique contexts for vectorization\n",
    "document_texts = list(set(doc[\"context\"] for doc in documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '0', 'context': 'business context, what factors influence work-life integration?', 'answer': 'Associating a product with a strong existing trigger outside its normal habitat, like pairing a candy with coffee breaks, can increase verbal mentions by linking it to something regularly thought of in a new context.'}, {'id': '1', 'context': 'business context, what factors influence work-life integration?', 'answer': 'For contracts that are valued at $500,000 a federal prime contractor must submit a subcontracting plan that includes a plan for the use of woman- owned businesses.'}, {'id': '2', 'context': 'business context, what factors influence work-life integration?', 'answer': 'Set personal goals, make realistic plans, and lean on advisors.'}, {'id': '3', 'context': 'business context, what factors influence work-life integration?', 'answer': 'Consider emotional/ psychological sides of change.'}, {'id': '4', 'context': 'business context, what factors influence work-life integration?', 'answer': 'Anticipate roadblocks, collaborate on priorities, hold sessions to find solutions.'}]\n"
     ]
    }
   ],
   "source": [
    "# samples\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pre-trained transformer model to create embeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed text\n",
    "\n",
    "def embed_text(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**tokens).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings and upsert to Pinecone\n",
    "# 1st approach: Embed the 'context' (question) for each document\n",
    "\n",
    "for doc in documents:\n",
    "    # Assuming you want to embed the 'context' (question)\n",
    "    embedding = embed_text(doc[\"context\"])  # Using 'context' for embedding\n",
    "    index.upsert([(doc[\"id\"], embedding, {\"text\": doc[\"context\"]})])  # Store 'context' in Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd approach: Store Both Context and Answer\n",
    "\n",
    "# Generate embeddings and upsert to Pinecone\n",
    "for doc in documents:\n",
    "    embedding = embed_text(doc[\"context\"])  # Using 'context' for embedding\n",
    "    index.upsert([\n",
    "        (\n",
    "            doc[\"id\"], \n",
    "            embedding, \n",
    "            {\"context\": doc[\"context\"], \"answer\": doc[\"answer\"]}  # Store both context and answer\n",
    "        )\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "\n",
    "# Generate embeddings and batch upsert to Pinecone\n",
    "batch_size = 100  # Adjust based on your dataset size and system capacity\n",
    "batches = [documents[i:i + batch_size] for i in range(0, len(documents), batch_size)]\n",
    "\n",
    "for batch in batches:\n",
    "    upserts = []\n",
    "    for doc in batch:\n",
    "        # Ensure 'context' and 'answer' keys exist\n",
    "        context = doc.get(\"context\", \"\")\n",
    "        answer = doc.get(\"answer\", \"\")\n",
    "        \n",
    "        # Embed the context\n",
    "        embedding = embed_text(context)\n",
    "        \n",
    "        # Add to upserts\n",
    "        upserts.append((doc[\"id\"], embedding, {\"context\": context, \"answer\": answer}))\n",
    "    \n",
    "    # Perform batch upsert\n",
    "    index.upsert(upserts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build QA Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 1st approach: Embed the 'context' (question) for each document\n",
    "\n",
    "def answer_query(query):\n",
    "    try:\n",
    "        # Embed the user query\n",
    "        query_embedding = embed_text(query)\n",
    "    \n",
    "        # Search Pinecone for similar contexts\n",
    "        search_results = index.query(\n",
    "            vector=query_embedding, \n",
    "            top_k=3, \n",
    "            include_metadata=True\n",
    "        )\n",
    "    \n",
    "        # Combine retrieved contexts\n",
    "        context = \"\\n\".join([result[\"metadata\"][\"context\"] for result in search_results[\"matches\"]])\n",
    "    \n",
    "        # Generate an answer using OpenAI\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"gpt-4\", \n",
    "            prompt=f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\",\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"I'm sorry, I couldn't process your request at the moment.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2nd approach: Store Both Context and Answer\n",
    "\n",
    "def answer_query(query):\n",
    "    try:\n",
    "        # Embed the user query\n",
    "        query_embedding = embed_text(query)\n",
    "    \n",
    "        # Search Pinecone for similar contexts\n",
    "        search_results = index.query(\n",
    "            vector=query_embedding, \n",
    "            top_k=3, \n",
    "            include_metadata=True\n",
    "        )\n",
    "    \n",
    "        # Check if answers are directly available from Pinecone\n",
    "        retrieved_answers = [result[\"metadata\"].get(\"answer\", \"\") for result in search_results[\"matches\"]]\n",
    "        retrieved_contexts = [result[\"metadata\"].get(\"context\", \"\") for result in search_results[\"matches\"]]\n",
    "        \n",
    "        # Combine retrieved contexts\n",
    "        combined_context = \"\\n\".join(retrieved_contexts)\n",
    "        \n",
    "        # If retrieved answers are sufficient and relevant, use them directly\n",
    "        if all(retrieved_answers):\n",
    "            return \"\\n\".join(retrieved_answers)\n",
    "        \n",
    "        # Otherwise, use OpenAI to generate a response based on the context\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"gpt-4\", \n",
    "            prompt=f\"Context: {combined_context}\\n\\nQuestion: {query}\\nAnswer:\",\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"I'm sorry, I couldn't process your request at the moment.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_query(query_embedding):\n",
    "    try:\n",
    "        # Ensure query_embedding is a 1D list\n",
    "        if isinstance(query_embedding, np.ndarray):\n",
    "            query_embedding = query_embedding.tolist()\n",
    "        elif not isinstance(query_embedding, list):\n",
    "            raise ValueError(\"query_embedding must be a list or numpy array\")\n",
    "\n",
    "        # Query Pinecone\n",
    "        search_results = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=3,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        # print(\"Search results:\", search_results)\n",
    "        return search_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Pinecone query: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test QA Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "question: What are the key factors affecting work-life balance?\n",
      "---------------------------------------------\n",
      "response:\n",
      "context: business context, what factors influence work-life integration?\n",
      "answer: Recognizing achievements through celebrations and promotions motivates employees and fuels innovation.\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# single output\n",
    "\n",
    "query = \"What are the key factors affecting work-life balance?\"\n",
    "query_embedding = embed_text(query)\n",
    "\n",
    "search_results = perform_query(query_embedding)\n",
    "\n",
    "if search_results:\n",
    "    best_match = max(search_results[\"matches\"], key=lambda match: match[\"score\"])\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"question: {query}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"response:\")\n",
    "    print(f\"context: {best_match['metadata']['context']}\")\n",
    "    print(f\"answer: {best_match['metadata']['answer']}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 96, Score: 0.664621949, Metadata: {'answer': 'Recognizing achievements through celebrations and promotions motivates employees and fuels innovation.', 'context': 'business context, what factors influence work-life integration?'}\n",
      "ID: 94, Score: 0.664621949, Metadata: {'answer': \"C rises force innovation, as Sk ylab's damaged launch did by requiring fast, creative solutions.\", 'context': 'business context, what factors influence work-life integration?'}\n",
      "ID: 95, Score: 0.664621949, Metadata: {'answer': 'When people are mutually accountable for results, there is less room for blame and self-justification.', 'context': 'business context, what factors influence work-life integration?'}\n"
     ]
    }
   ],
   "source": [
    "# get top 3 raw results\n",
    "\n",
    "query = \"What are the key factors affecting work-life balance?\"\n",
    "query_embedding = embed_text(query)\n",
    "\n",
    "search_results = perform_query(query_embedding)\n",
    "if search_results:\n",
    "    for match in search_results[\"matches\"]:\n",
    "        print(f\"ID: {match['id']}, Score: {match['score']}, Metadata: {match['metadata']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the index if no longer needed\n",
    "\n",
    "pinecone_client.delete_index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
