{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# off-the-shelf sentiment analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the off-the-shelf sentiment analysis pipeline\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Example texts \n",
    "\n",
    "texts = [\"I loved this movie\", \"This movie was terrible\", \"This movie was the worst movie I have ever seen\"]\n",
    "\n",
    "# Perform sentiment analysis \n",
    "\n",
    "results_off_the_shelf = sentiment_analysis(texts)\n",
    "\n",
    "# Print the results\n",
    "\n",
    "for text, result in zip(texts, results_off_the_shelf):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result['label']}\")\n",
    "    print(f\"Confidence: {result['score']}\")\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the TextBlob library to perform sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the IMDb dataset\n",
    "max_words = 10000  # Only consider the top 10,000 most frequent words\n",
    "max_len = 200  # Pad sequences to a maximum length of 200 words\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)\n",
    "\n",
    "# Convert IMDb integer sequences back to words for TextBlob\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {v: k for k, v in word_index.items()}\n",
    "\n",
    "# Function to decode sequences back to text\n",
    "def decode_review(text_sequence):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text_sequence])\n",
    "\n",
    "# Decode some test sequences to evaluate with TextBlob\n",
    "X_test_texts = [decode_review(sequence) for sequence in X_test[:1000]]  # Evaluate 1000 reviews\n",
    "\n",
    "# Prepare input data for deep learning models (LSTM/GRU)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "# Use TextBlob for sentiment analysis on the test data\n",
    "textblob_sentiments = []\n",
    "\n",
    "for review in X_test_texts:\n",
    "    blob = TextBlob(review)\n",
    "    # TextBlob returns polarity: -1 (negative), 1 (positive), 0 (neutral)\n",
    "    sentiment_score = blob.sentiment.polarity\n",
    "    # Convert polarity to binary sentiment (similar to LSTM/GRU model)\n",
    "    sentiment_label = 1 if sentiment_score > 0 else 0  # 1: positive, 0: negative\n",
    "    textblob_sentiments.append(sentiment_label)\n",
    "\n",
    "# TextBlob predicted labels\n",
    "textblob_sentiments = np.array(textblob_sentiments)\n",
    "\n",
    "# Evaluate TextBlob accuracy\n",
    "textblob_accuracy = np.mean(textblob_sentiments == y_test[:1000])\n",
    "print(f\"TextBlob Sentiment Analysis Accuracy: {textblob_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/hi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data] Downloading package stopwords to /Users/hi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/hi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.util import accuracy as nltk_accuracy\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import random\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.data.path.append('/Users/hi/jitenStuff/MyGit/AI-ML-DL/.venv/nltk_data')\n",
    "nltk.download(\"movie_reviews\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.75\n",
      "Most Informative Features\n",
      "                 idiotic = True              neg : pos    =     19.0 : 1.0\n",
      "               marvelous = True              pos : neg    =     14.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     12.6 : 1.0\n",
      "               stupidity = True              neg : pos    =     11.4 : 1.0\n",
      "             outstanding = True              pos : neg    =     11.4 : 1.0\n",
      "              astounding = True              pos : neg    =     11.0 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.0 : 1.0\n",
      "             fascination = True              pos : neg    =      9.6 : 1.0\n",
      "              henstridge = True              neg : pos    =      9.0 : 1.0\n",
      "                  random = True              neg : pos    =      9.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "def extract_features(words):\n",
    "    return {word: True for word in words}\n",
    "\n",
    "documents = [\n",
    "    (list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)\n",
    "]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "featuresets = [(extract_features(d), c) for (d, c) in documents]\n",
    "train_set, test_set = featuresets[:1600], featuresets[1600:]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "accuracy = nltk_accuracy(classifier, test_set)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_sentiment(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]  # Remove punctuation and stopwords\n",
    "    features = extract_features(words)\n",
    "    \n",
    "    return classifier.classify(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I love this movie\n",
      "Sentiment: pos\n",
      "-------------------------\n",
      "Sentence: I hate this movie\n",
      "Sentiment: neg\n",
      "-------------------------\n",
      "Sentence: the movie was terrible\n",
      "Sentiment: neg\n",
      "-------------------------\n",
      "Sentence: the movie was horrible\n",
      "Sentiment: neg\n",
      "-------------------------\n",
      "Sentence: I didn't like the movie\n",
      "Sentiment: neg\n",
      "-------------------------\n",
      "Sentence: fantastic movie\n",
      "Sentiment: pos\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"I love this movie\", \n",
    "    \"I hate this movie\", \n",
    "    \"the movie was terrible\", \n",
    "    \"the movie was horrible\",\n",
    "    \"I didn't like the movie\",\n",
    "    \"fantastic movie\",\n",
    "]\n",
    "\n",
    "for sentence in test_inputs:\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {analyse_sentiment(sentence)}\")\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
